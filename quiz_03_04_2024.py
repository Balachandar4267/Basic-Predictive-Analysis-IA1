# -*- coding: utf-8 -*-
"""QUIZ 03/04/2024.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cTL0DN8cuW9KPX4lGOaZFm0YVyZXtHFQ
"""

from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest

df = pd.read_csv("/content/sample_data/DSAI-LVA-DATASET for Quiz.csv")
df.info()

def pass_criteria(scores):
  if(scores >70):
    return "Passed with high grade"
  elif(50 < scores < 60):
    return "passed with low grade"
  else:
    return "failed"
df["pass_criteria"] = df["PreviousTestScore"].apply(pass_criteria)
df.info()
df.head()

def generate_random_education(educations):
    if educations == "HighSchool":
        return np.random.choice(["High School", "School"])
    elif educations == "College":
        return np.random.choice(["Bachelors", "Masters"])
    else:
        return np.random.choice(["Not educated"])
df["ParentEducation_criteria"] = df["ParentEducation"].apply(generate_random_education)
df.head()

df.drop("ParentEducation",inplace =True,axis = 1)
df.head()

df_v = pd.get_dummies(df,columns =['Pass','pass_criteria','ParentEducation_criteria'])

df_v.drop("Pass_No",inplace = True,axis =1)
df_v.drop("pass_criteria_failed",inplace = True,axis =1)
df_v.drop("pass_criteria_passed with low grade",inplace = True,axis =1)
df_v.drop("ParentEducation_criteria_High School",inplace = True,axis =1)
df_v.drop("ParentEducation_criteria_Masters",inplace = True,axis =1)
df_v.drop("ParentEducation_criteria_School",inplace = True,axis =1)
#df_v.drop("Pass_No",inplace = True,axis =1)
df_v.head()

total_rows = len(df_v)
train_ratio = 0.7
train_size = int(total_rows * train_ratio)
test_size = total_rows - train_size

df_shuffled = df_v.sample(frac=1, random_state=42)

train_data = df_shuffled.head(train_size)
test_data = df_shuffled.tail(test_size)

train_data.to_csv("/content/sample_data/train_data_quiz.csv")
test_data.to_csv("/content/sample_data/test_data_quiz.csv")

df_train = pd.read_csv("/content/sample_data/train_data_quiz.csv")
df_train.head()

X = df_train[['StudyTime','PreviousTestScore','Pass_Yes','ParentEducation_criteria_Bachelors']]
y = df_train['pass_criteria_Passed with high grade']

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 42)


clf_decisison_tree = DecisionTreeClassifier()
clf_decisison_tree.fit(X_train,y_train)
clf_decisison_tree_predict = clf_decisison_tree.predict(X_test)
a = accuracy_score(y_test,clf_decisison_tree_predict)
print("The accuracy score of DecisionTree:",accuracy_score(y_test,clf_decisison_tree_predict))


clf_randomstate = RandomForestClassifier()
clf_randomstate.fit(X_train,y_train)
clf_randomstate_predict = clf_randomstate.predict(X_test)
b= accuracy_score(y_test,clf_randomstate_predict)
print("The accuracy score of RandomForest:",accuracy_score(y_test,clf_randomstate_predict))


clf_XGBoost = XGBClassifier()
clf_XGBoost.fit(X_train,y_train)
clf_XGBoost_predict = clf_XGBoost.predict(X_test)
c=accuracy_score(y_test,clf_XGBoost_predict)
print("The accuracy score of XGBOOST:",accuracy_score(y_test,clf_XGBoost_predict))

x = ["decision_tree","Random_forest","XG BOOST"]
y = [a,b,c]
plt.figure(figsize=(8,6))
plt.bar(x,y,color = 'g')
plt.xlabel("Classifiers")
plt.ylabel("Accuracy score")
plt.grid(False)
plt.plot()